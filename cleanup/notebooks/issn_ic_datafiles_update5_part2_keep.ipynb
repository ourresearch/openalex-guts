{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update5 - TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140473786356096: loading merged_into_institutions_dict\n",
      "140473786356096: loading valid concept IDs\n",
      "140473786356096: loading valid topic IDs\n"
     ]
    }
   ],
   "source": [
    "from app import db\n",
    "from models import Source, ISSNtoISSNL\n",
    "from models.source import DELETED_SOURCE_ID\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.orm import Load\n",
    "from sqlalchemy.exc import MultipleResultsFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanup.util import make_request, paginate_openalex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 738 ms, sys: 203 ms, total: 941 ms\n",
      "Wall time: 2.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sq = \"\"\"select if.*, ife.cluster_title from issn_audit_20240321.issn_ic_datafile_202402 if\n",
    "left join issn_audit_20240321.issn_ic_datafile_expanded_202402 ife\n",
    "  on if.\"submitted_1348-0278\"  = ife.issns;\"\"\"\n",
    "df_issnl_file = pd.read_sql_query(sq, db.engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issnl_file = df_issnl_file.rename(columns={\"submitted_1348-0278\": \"submitted_issn\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 66.5 ms, total: 1.88 s\n",
      "Wall time: 3.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sq = \"\"\"select journal_id, display_name, issn, issns, issns_text_array, type, country_code, alternate_titles, publisher_id\n",
    "    from mid.journal\n",
    "    where merge_into_id is null\"\"\"\n",
    "df_midjournal = pd.read_sql_query(sq, db.engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258555\n",
      "145308\n"
     ]
    }
   ],
   "source": [
    "print(len(df_midjournal))\n",
    "df_midjournal.dropna(subset='issn', inplace=True)\n",
    "print(len(df_midjournal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/145308 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145308/145308 [00:00<00:00, 1269371.60it/s]\n"
     ]
    }
   ],
   "source": [
    "smap = {}\n",
    "for source_id, issn_list in tqdm(df_midjournal.set_index('journal_id', verify_integrity=True)['issns_text_array'].items(), total=len(df_midjournal)):\n",
    "    for issn in issn_list:\n",
    "        if issn in smap:\n",
    "            smap[issn].append(source_id)\n",
    "        else:\n",
    "            smap[issn] = [source_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for issn, source_list in smap.items():\n",
    "    d.append({\n",
    "        'issn': issn,\n",
    "        'num_sources': len(source_list),\n",
    "    })\n",
    "_df = pd.DataFrame(d)\n",
    "_df['num_sources'].value_counts()\n",
    "df_issnl_file['num_sources_resolve'] = df_issnl_file['submitted_issn'].map(_df.set_index('issn', verify_integrity=True)['num_sources'])\n",
    "df_issnl_file['num_sources_resolve'].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual_works_count = []\n",
    "# subset = {issn: source_list for issn, source_list in smap.items() if len(source_list) > 1}\n",
    "# for issn, source_list in tqdm(subset.items()):\n",
    "#     if len(source_list) > 1:\n",
    "#         for source_id in source_list:\n",
    "#             url = f'https://api.openalex.org/works?filter=locations.source.id:S{source_id}'\n",
    "#             params = {'mailto': 'jportenoy@ourresearch.org',\n",
    "#                       'select': 'id',\n",
    "#                       'per-page': 1}\n",
    "#             r = make_request(url, params=params)\n",
    "#             this_c = r.json()['meta']['count']\n",
    "#             actual_works_count.append({\n",
    "#                 'issn': issn,\n",
    "#                 'source_id': source_id,\n",
    "#                 'works_count': this_c,\n",
    "#             })\n",
    "# df_actual_works_count = pd.DataFrame(actual_works_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual_works_count = pd.read_pickle('../data/issn_audit_20240301/df_actual_works_count.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_actual_works_count[['source_id', 'works_count']].drop_duplicates()\n",
    "x = x.set_index('source_id', verify_integrity=True)['works_count']\n",
    "df_midjournal['works_count'] = df_midjournal['journal_id'].map(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.29 s, sys: 295 ms, total: 8.58 s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "url = \"https://api.openalex.org/sources\"\n",
    "params = {\n",
    "    'mailto': 'jportenoy@ourresearch.org',\n",
    "    'group_by': 'issn',\n",
    "}\n",
    "data = []\n",
    "for r in paginate_openalex(url, params=params):\n",
    "    data.extend(r.json()['group_by'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sources = pd.DataFrame(data)\n",
    "_rename = {\n",
    "    'key': 'issn',\n",
    "    'count': 'num_sources_in_openalex',\n",
    "}\n",
    "df_openalex_issn_sources_count = df_sources.rename(columns=_rename).drop(columns=['key_display_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_sources_in_openalex\n",
       "1    209737\n",
       "2      8239\n",
       "3       149\n",
       "4         6\n",
       "5         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openalex_issn_sources_count['num_sources_in_openalex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issn_to_issnl = pd.read_sql_query(\"\"\"select * from mid.journal_issn_to_issnl\"\"\", db.engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "issn_to_issnl = df_issn_to_issnl.set_index('issn', verify_integrity=True)['issnl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "issnls = issn_to_issnl.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sources_db(issn, session):\n",
    "    sources1 = session.query(Source).options(Load(Source).lazyload('*')).filter_by(merge_into_id=None).filter_by(issn=issn).all()\n",
    "    sources2 = session.query(Source).options(Load(Source).lazyload('*')).filter_by(merge_into_id=None).filter(Source.issns.contains(issn)).all()\n",
    "    return set(sources1 + sources2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     dups_data = {}\n",
    "#     num_sources_verify = []\n",
    "#     works_count_map = df_midjournal.set_index('journal_id', verify_integrity=True)['works_count']\n",
    "#     for issn, row in tqdm(df_mult.set_index('issn', verify_integrity=True).iterrows(), total=len(df_mult)):\n",
    "#         this_issn_data = []\n",
    "#         sources = get_all_sources_db(issn, db.session)\n",
    "#         num_sources_verify.append({\n",
    "#             'issn': issn,\n",
    "#             'num_sources_in_openalex': row['num_sources_in_openalex'],\n",
    "#             'num_sources_db': len(sources),\n",
    "#         })\n",
    "#         for source in sources:\n",
    "#             fuzzratio = rapidfuzz.fuzz.ratio(source.display_name, row['title'], processor=rapidfuzz.utils.default_process)\n",
    "#             this_issn_data.append({\n",
    "#                 'source_id': source.id,\n",
    "#                 'fuzzratio': fuzzratio,\n",
    "#                 'works_count': works_count_map[source.id]\n",
    "#             })\n",
    "#         dups_data[issn] = this_issn_data\n",
    "# finally:\n",
    "#     db.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = Path('../data/issn_audit_20240301/dups_data.pickle')\n",
    "dups_data = pickle.loads(fp.read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3756\n",
      "3736\n",
      "1823\n",
      "3736\n"
     ]
    }
   ],
   "source": [
    "issnldups = df_midjournal.dropna(subset='issn')\n",
    "issnldups = issnldups[issnldups['issn'].duplicated(keep=False)]\n",
    "print(len(issnldups))\n",
    "issnldups = issnldups[issnldups['issn'].isin(issnls)]\n",
    "print(len(issnldups))\n",
    "print(issnldups['issn'].nunique())\n",
    "print(issnldups['journal_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through each of these above (groupby issn, which should be the issnl), and dedup. delete any which aren't issnls (maybe check them for data later).\n",
    "#add missing sources from data file (any issnl that doesn't have a source_id identified by issnl)\n",
    "#this should leave us with no duplicate issns\n",
    "#then figure out how to resolve any issns that resolve to multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just merge all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1823 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1823/1823 [19:02<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1897 updated\n",
      "CPU times: user 38 s, sys: 1.02 s, total: 39.1 s\n",
      "Wall time: 19min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    num_updated = 0\n",
    "    n_issn = issnldups['issn'].nunique()\n",
    "    no_dd_found = []\n",
    "    not_actually_dups = []\n",
    "    for issn, gbdf in tqdm(issnldups.set_index('journal_id', verify_integrity=True).groupby('issn'), total=n_issn):\n",
    "        now = datetime.now(timezone.utc).isoformat()\n",
    "        try:\n",
    "            dd = dups_data[issn]\n",
    "        except KeyError:\n",
    "            no_dd_found.append(issn)\n",
    "            continue\n",
    "        if len(dd) < 2:\n",
    "            # come back to these\n",
    "            not_actually_dups.append(issn)\n",
    "            continue\n",
    "        # sort by [works_count:desc, source_id:asc]\n",
    "        dd.sort(key=lambda x: x['source_id'])\n",
    "        dd.sort(key=lambda x: x['works_count'], reverse=True)\n",
    "\n",
    "        merge_into_id = dd[0]['source_id']\n",
    "        for item in dd[1:]:\n",
    "            id_to_merge = item['source_id']\n",
    "            source = db.session.query(Source).filter_by(journal_id=id_to_merge).one()\n",
    "            source.merge_into_id = merge_into_id\n",
    "            source.merge_into_date = now\n",
    "            source.updated_date = now\n",
    "\n",
    "            db.session.add(source)\n",
    "\n",
    "            note = f\"merged because duplicate issnl.\"\n",
    "            row = gbdf.loc[id_to_merge].fillna(value=0)\n",
    "            if row['publisher_id'] or row['alternate_titles']:\n",
    "                note += \" may have additional info.\"\n",
    "\n",
    "            sq = \"\"\"INSERT INTO issn_audit_20240321.update5\n",
    "                    (source_id, updated_date, merge_into_id, note)\n",
    "                    VALUES(:source_id, :now, :merge_into_id, :note);\"\"\"\n",
    "            db.session.execute(text(sq), {\n",
    "                'source_id': source.id,\n",
    "                'now': now,\n",
    "                'merge_into_id': merge_into_id,\n",
    "                'note': note,\n",
    "            })\n",
    "\n",
    "            sq = \"\"\"update issn_audit_20240321.issn_ic_datafile_202402 set resolved = true\n",
    "                where \"submitted_1348-0278\" = :issn\"\"\"\n",
    "            db.session.execute(text(sq), {\n",
    "                'issn': issn,\n",
    "            })\n",
    "\n",
    "            num_updated += 1\n",
    "    db.session.commit()\n",
    "    print(f\"{num_updated} updated\")\n",
    "finally:\n",
    "    db.session.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0287-3478',\n",
       " '0342-5932',\n",
       " '0387-1185',\n",
       " '0392-5005',\n",
       " '0393-134X',\n",
       " '0716-2006',\n",
       " '0767-709X',\n",
       " '0950-5571',\n",
       " '1025-3076',\n",
       " '1121-4074',\n",
       " '1437-9309',\n",
       " '1727-1584',\n",
       " '1996-0042',\n",
       " '2084-7998',\n",
       " '2521-7119']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "no_dd_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_actually_dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  6.64it/s]\n"
     ]
    }
   ],
   "source": [
    "no_dd_sources = {}\n",
    "for issn in tqdm(no_dd_found):\n",
    "    no_dd_sources[issn] = get_all_sources_db(issn, db.session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0287-3478': {<Source ( http://localhost:5007/S2764753162?apiurls ) 2764753162 Crustacean research>,\n",
       "  <Source ( http://localhost:5007/S4386621722?apiurls ) 4386621722 Crustacean Research>},\n",
       " '0342-5932': {<Source ( http://localhost:5007/S4306535007?apiurls ) 4306535007 Würzburger Jahrbücher für die Altertumswissenschaft>,\n",
       "  <Source ( http://localhost:5007/S4393914634?apiurls ) 4393914634 Würzburger Jahrbücher für die Altertumswissenschaft (Internet)>},\n",
       " '0387-1185': {<Source ( http://localhost:5007/S2764951900?apiurls ) 2764951900 Transactions of the Architectural Institute of Japan>,\n",
       "  <Source ( http://localhost:5007/S4386621727?apiurls ) 4386621727 Transactions of the Architectural Institute of Japan>},\n",
       " '0392-5005': {<Source ( http://localhost:5007/S4306533961?apiurls ) 4306533961 URBANISTICA INFORMAZIONI>,\n",
       "  <Source ( http://localhost:5007/S4393915153?apiurls ) 4393915153 Urbanistica informazioni (Online)>},\n",
       " '0393-134X': {<Source ( http://localhost:5007/S4306518029?apiurls ) 4306518029 LA LEGISLAZIONE PENALE>,\n",
       "  <Source ( http://localhost:5007/S4393915164?apiurls ) 4393915164 La Legislazione penale (Online)>},\n",
       " '0716-2006': {<Source ( http://localhost:5007/S4306506282?apiurls ) 4306506282 Ciencia y Tecnología del Mar>,\n",
       "  <Source ( http://localhost:5007/S4393915626?apiurls ) 4393915626 Ciencia y tecnología del mar (En línea)>},\n",
       " '0767-709X': {<Source ( http://localhost:5007/S4210192068?apiurls ) 4210192068 Revue archéologique de l'Ouest>,\n",
       "  <Source ( http://localhost:5007/S4306528123?apiurls ) 4306528123 Revue Archéologique de l'Ouest>,\n",
       "  <Source ( http://localhost:5007/S4386621721?apiurls ) 4386621721 Revue archéologique de l Ouest>},\n",
       " '0950-5571': {<Source ( http://localhost:5007/S4392228800?apiurls ) 4392228800 Medical History Supplements>,\n",
       "  <Source ( http://localhost:5007/S4393916367?apiurls ) 4393916367 Medical history. Supplement>},\n",
       " '1025-3076': {<Source ( http://localhost:5007/S4306512670?apiurls ) 4306512670 ICIDCA Sobre los Derivados de la Caña de Azúcar>,\n",
       "  <Source ( http://localhost:5007/S4393916609?apiurls ) 4393916609 ICIDCA sobre los derivados de la caña de azúcar (En línea)>},\n",
       " '1121-4074': {<Source ( http://localhost:5007/S4306528604?apiurls ) 4306528604 Rivista di diritto tributario>,\n",
       "  <Source ( http://localhost:5007/S4306528605?apiurls ) 4306528605 RIVISTA DI DIRITTO TRIBUTARIO>,\n",
       "  <Source ( http://localhost:5007/S4393917092?apiurls ) 4393917092 Rivista di diritto tributario (Online)>},\n",
       " '1437-9309': {<Source ( http://localhost:5007/S4306518789?apiurls ) 4306518789 Literaturkritik.de>,\n",
       "  <Source ( http://localhost:5007/S4393917365?apiurls ) 4393917365 Literaturkritik.de (Internet)>},\n",
       " '1727-1584': {<Source ( http://localhost:5007/S4210222736?apiurls ) 4210222736 Право і безпека>,\n",
       "  <Source ( http://localhost:5007/S4386621731?apiurls ) 4386621731 Law and Safety>},\n",
       " '1996-0042': {<Source ( http://localhost:5007/S4306524739?apiurls ) 4306524739 Protokolle zur Bibel>,\n",
       "  <Source ( http://localhost:5007/S4393918019?apiurls ) 4393918019 Protokolle zur Bibel (Internet)>},\n",
       " '2084-7998': {<Source ( http://localhost:5007/S4210178752?apiurls ) 4210178752 Journal of Preschool and Elementary School Education>,\n",
       "  <Source ( http://localhost:5007/S4393918136?apiurls ) 4393918136 Journal of Preschool and Elementary School Education>},\n",
       " '2521-7119': {<Source ( http://localhost:5007/S4220651409?apiurls ) 4220651409 Proceedings of the IAHR World Congress>,\n",
       "  <Source ( http://localhost:5007/S4385749601?apiurls ) 4385749601 8th IAHR World Congress - \"Water: Connecting the World\">}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_dd_sources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
